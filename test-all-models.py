#!/usr/bin/env python3
import json
import urllib.request
import time

class ModelTester:
    def __init__(self):
        self.account_id = '30fdf13d5bb71a81bc6f7c732f244a72'
        self.api_token = 'yuQYV5OLqM6FD6x017d1K_9OxtJF2ytnGU2kJ3y6'
        self.google_api_key = 'AIzaSyCHXQsENnN8ilwrdWqDartcHOvptRsqetA'
        
        self.cloudflare_models = [
            '@cf/meta/llama-3-8b-instruct',
            '@cf/meta/llama-3-70b-instruct',
            '@cf/mistral/mistral-7b-instruct-v0.2'
        ]
        
        self.gemini_models = [
            'gemini-2.5-pro',
            'gemini-2.0-flash',
            'gemini-1.5-pro'
        ]
        
        self.test_message = "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
    
    def test_cloudflare_model(self, model):
        print(f"\n{'='*60}")
        print(f"æµ‹è¯•æ¨¡å‹: {model}")
        print(f"{'='*60}")
        
        try:
            start_time = time.time()
            
            messages = [
                {
                    'role': 'system',
                    'content': 'ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ AI åŠ©æ‰‹ï¼Œä½¿ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚'
                },
                {
                    'role': 'user',
                    'content': self.test_message
                }
            ]
            
            api_url = f'https://api.cloudflare.com/client/v4/accounts/{self.account_id}/ai/run/{model}'
            
            req = urllib.request.Request(
                api_url,
                data=json.dumps({
                    'messages': messages,
                    'max_tokens': 100,
                    'temperature': 0.7
                }).encode('utf-8'),
                headers={
                    'Content-Type': 'application/json',
                    'Authorization': f'Bearer {self.api_token}'
                }
            )
            
            with urllib.request.urlopen(req) as response:
                response_data = json.loads(response.read().decode('utf-8'))
                elapsed_time = time.time() - start_time
                
                if response_data.get('success'):
                    result = response_data.get('result', {})
                    ai_response = result.get('response', '')
                    usage = result.get('usage', {})
                    
                    print(f"âœ… çŠ¶æ€: æˆåŠŸ")
                    print(f"â±ï¸  å“åº”æ—¶é—´: {elapsed_time:.2f} ç§’")
                    print(f"ğŸ“Š Token ä½¿ç”¨:")
                    print(f"   - è¾“å…¥: {usage.get('prompt_tokens', 0)}")
                    print(f"   - è¾“å‡º: {usage.get('completion_tokens', 0)}")
                    print(f"   - æ€»è®¡: {usage.get('total_tokens', 0)}")
                    print(f"\nğŸ’¬ AI å›å¤:")
                    print(f"   {ai_response[:200]}{'...' if len(ai_response) > 200 else ''}")
                    
                    return {
                        'model': model,
                        'success': True,
                        'response_time': elapsed_time,
                        'usage': usage,
                        'response': ai_response
                    }
                else:
                    print(f"âŒ çŠ¶æ€: å¤±è´¥")
                    print(f"é”™è¯¯: {response_data.get('errors', [])}")
                    return {
                        'model': model,
                        'success': False,
                        'error': response_data.get('errors', [])
                    }
                    
        except urllib.error.HTTPError as e:
            print(f"âŒ HTTP é”™è¯¯: {e.code} - {e.reason}")
            return {
                'model': model,
                'success': False,
                'error': f"HTTP {e.code}: {e.reason}"
            }
        except Exception as e:
            print(f"âŒ é”™è¯¯: {str(e)}")
            return {
                'model': model,
                'success': False,
                'error': str(e)
            }
    
    def test_gemini_model(self, model):
        print(f"\n{'='*60}")
        print(f"æµ‹è¯•æ¨¡å‹: {model}")
        print(f"{'='*60}")
        
        try:
            start_time = time.time()
            
            model_map = {
                'gemini-2.5-pro': 'gemini-2.5-pro',
                'gemini-2.0-flash': 'gemini-2.0-flash',
                'gemini-1.5-pro': 'gemini-1.5-pro'
            }
            
            selected_model = model_map.get(model, 'gemini-2.0-flash')
            
            contents = [
                {
                    'role': 'user',
                    'parts': [
                        {
                            'text': 'ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ AI åŠ©æ‰‹ï¼Œä½¿ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚'
                        }
                    ]
                },
                {
                    'role': 'user',
                    'parts': [
                        {
                            'text': self.test_message
                        }
                    ]
                }
            ]
            
            api_url = f'https://generativelanguage.googleapis.com/v1beta/models/{selected_model}:generateContent?key={self.google_api_key}'
            
            req = urllib.request.Request(
                api_url,
                data=json.dumps({
                    'contents': contents,
                    'generationConfig': {
                        'temperature': 0.7,
                        'maxOutputTokens': 100
                    }
                }).encode('utf-8'),
                headers={
                    'Content-Type': 'application/json'
                }
            )
            
            with urllib.request.urlopen(req) as response:
                response_data = json.loads(response.read().decode('utf-8'))
                elapsed_time = time.time() - start_time
                
                if 'candidates' in response_data and len(response_data['candidates']) > 0:
                    candidate = response_data['candidates'][0]
                    ai_response = candidate.get('content', {}).get('parts', [{}])[0].get('text', '')
                    usage_metadata = response_data.get('usageMetadata', {})
                    
                    print(f"âœ… çŠ¶æ€: æˆåŠŸ")
                    print(f"â±ï¸  å“åº”æ—¶é—´: {elapsed_time:.2f} ç§’")
                    print(f"ğŸ“Š Token ä½¿ç”¨:")
                    print(f"   - è¾“å…¥: {usage_metadata.get('promptTokenCount', 0)}")
                    print(f"   - è¾“å‡º: {usage_metadata.get('candidatesTokenCount', 0)}")
                    print(f"   - æ€»è®¡: {usage_metadata.get('totalTokenCount', 0)}")
                    print(f"\nğŸ’¬ AI å›å¤:")
                    print(f"   {ai_response[:200]}{'...' if len(ai_response) > 200 else ''}")
                    
                    return {
                        'model': model,
                        'success': True,
                        'response_time': elapsed_time,
                        'usage': usage_metadata,
                        'response': ai_response
                    }
                else:
                    print(f"âŒ çŠ¶æ€: å¤±è´¥")
                    print(f"é”™è¯¯: {response_data}")
                    return {
                        'model': model,
                        'success': False,
                        'error': response_data
                    }
                    
        except urllib.error.HTTPError as e:
            print(f"âŒ HTTP é”™è¯¯: {e.code} - {e.reason}")
            return {
                'model': model,
                'success': False,
                'error': f"HTTP {e.code}: {e.reason}"
            }
        except Exception as e:
            print(f"âŒ é”™è¯¯: {str(e)}")
            return {
                'model': model,
                'success': False,
                'error': str(e)
            }
    
    def test_all_models(self):
        print("\n" + "="*60)
        print("å¼€å§‹æµ‹è¯•æ‰€æœ‰æ¨¡å‹")
        print("="*60)
        
        results = {
            'cloudflare': [],
            'gemini': []
        }
        
        print("\nğŸ“¡ æµ‹è¯• Cloudflare Workers AI æ¨¡å‹")
        print("="*60)
        
        for model in self.cloudflare_models:
            result = self.test_cloudflare_model(model)
            results['cloudflare'].append(result)
            time.sleep(1)
        
        print("\n\nğŸ¤– æµ‹è¯• Google Gemini æ¨¡å‹")
        print("="*60)
        
        for model in self.gemini_models:
            result = self.test_gemini_model(model)
            results['gemini'].append(result)
            time.sleep(1)
        
        self.print_summary(results)
        
        return results
    
    def print_summary(self, results):
        print("\n\n" + "="*60)
        print("æµ‹è¯•ç»“æœæ±‡æ€»")
        print("="*60)
        
        print("\nğŸ“¡ Cloudflare Workers AI æ¨¡å‹:")
        print("-"*60)
        for result in results['cloudflare']:
            status = "âœ… æˆåŠŸ" if result['success'] else "âŒ å¤±è´¥"
            print(f"{result['model']}: {status}")
            if result['success']:
                print(f"   å“åº”æ—¶é—´: {result['response_time']:.2f} ç§’")
                print(f"   Token ä½¿ç”¨: {result['usage'].get('total_tokens', 0)}")
            else:
                print(f"   é”™è¯¯: {result['error']}")
        
        print("\nğŸ¤– Google Gemini æ¨¡å‹:")
        print("-"*60)
        for result in results['gemini']:
            status = "âœ… æˆåŠŸ" if result['success'] else "âŒ å¤±è´¥"
            print(f"{result['model']}: {status}")
            if result['success']:
                print(f"   å“åº”æ—¶é—´: {result['response_time']:.2f} ç§’")
                print(f"   Token ä½¿ç”¨: {result['usage'].get('totalTokenCount', 0)}")
            else:
                print(f"   é”™è¯¯: {result['error']}")
        
        print("\n" + "="*60)
        
        successful_count = sum(1 for r in results['cloudflare'] + results['gemini'] if r['success'])
        total_count = len(results['cloudflare']) + len(results['gemini'])
        
        print(f"æ€»è®¡: {successful_count}/{total_count} ä¸ªæ¨¡å‹æµ‹è¯•æˆåŠŸ")
        print("="*60)

if __name__ == '__main__':
    tester = ModelTester()
    results = tester.test_all_models()
    
    print("\n\nâœ… æµ‹è¯•å®Œæˆï¼")